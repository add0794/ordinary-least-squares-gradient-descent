{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ordinary Least Squares (OLS) vs. Gradient Descent (GD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Framing the Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple regression is a statistical technique used to model the relationship between one dependent variable (or label) and two or more independent variables (or features). It is a powerful tool for understanding how changes in independent variables influence the dependent variable. While this modeling approach can be implemented using various strategies, I will focus on two main methods: \n",
    "- **Ordinary Least Squares (OLS)**, which derives the solution through pure mathematical analysis, \n",
    "- **Gradient Descent (GD)**, an iterative optimization algorithm often associated with machine learning.\n",
    "\n",
    "Python packages exist for conducting multiple regression, but this article will show how to derive the regression parameters using both OLS and GD from scratch. \n",
    "\n",
    "However, both methods will compare their results to particular packages: \n",
    "- OLS with scipy vs. OLS with numpy\n",
    "- OLS vs. statsmodels\n",
    "- GD vs. scikit-learn\n",
    "\n",
    "All in all, this article will compare performance and applicability for multiple regression based on the following criteria:\n",
    "- **Computational Speed**: How quickly each method converges to a solution, particularly for datasets of varying sizes and dimensionalities.\n",
    "- **Memory Usage**: The amount of memory required by each approach, especially for large datasets where matrix operations (OLS) may become prohibitive.\n",
    "- **Convergence Behavior**: The robustness of GD to hyperparameter tuning (e.g., learning rate) and its ability to converge to an optimal solution in different conditions.\n",
    "- **Numerical Stability**: How each method performs when faced with ill-conditioned data or high multicollinearity among independent variables.\n",
    "- **Scalability**: Suitability for big data scenarios, where the efficiency of processing may differ significantly between the two methods.\n",
    "- **Ease of Implementation**: Practical considerations, including code complexity, ease of debugging, and availability of libraries or tools.\n",
    "- **Accuracy**: The ability of each method to minimize the error term (residuals) and produce reliable parameter estimates under different scenarios.\n",
    "\n",
    "By doing so, you'll get a sense of which scenario is preferable over the other. For example:\n",
    "- OLS may excel in smaller datasets where computational resources are not constrained.\n",
    "- GD is often the method of choice for very large datasets or when working with models that extend beyond linear regression, such as neural networks.\n",
    "\n",
    "By analyzing these aspects, this article aims to provide a comprehensive comparison to help readers choose the appropriate method for their specific use case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's focus on how the parameters are derived with OLS and GD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **How to Use Ordinary Least Squares (OLS)**\n",
    "\n",
    "#### **0) How to Get Started**\n",
    "\n",
    "We start with the following equation:\n",
    "\n",
    "$$Xβ = y$$\n",
    "\n",
    "Where:\n",
    "\n",
    "*X* := The design matrix of independent variables\\\n",
    "*β* := The vector of parameters (coefficients to be estimated)\\\n",
    "*y* := The vector of the dependent variable\n",
    "\n",
    "This is not possible, however, since there is always an error value, known as the *residuals*. \n",
    "\n",
    "Thus:\n",
    "\n",
    "$$X\\hat{β} + ε = \\hat{y}$$\n",
    "\n",
    "With that in mind, OLS can be derived through various approaches:\n",
    "\n",
    "#### **1) Optimization using calculus**  \n",
    "\n",
    "In this scenario, we minimize the norm of $y - \\hat{y}$, which will give us the vector of parameters. $$\\min_β |y - \\hat{y}| = \\min_β |y - X\\hat{β}|^2$$\n",
    "\n",
    "I won't do the math for this, but if you're interested, it requires calculus and is a stronger solution since it follows along the maximum likelihood estimation (MLE).\n",
    "\n",
    "#### **2) Using the Left Inverse**\n",
    "\n",
    "Because $Xβ$ is assumed to be full column rank, we can derive *β*.\n",
    "\n",
    "In other words, if we multiply $Xβ$ by its transpose, we can then multiply it by its inverse.\n",
    "\n",
    "Thus:\n",
    "\n",
    "$$X^TXβ = X^Ty$$\n",
    "$$(X^TX)^{-1}X^TXβ = (X^T X)^{-1}X^Ty$$\n",
    "$$Iβ = (X^TX)^{-1}X^Ty$$\n",
    "$$β = (X^T X)^{-1}X^Ty$$\n",
    "\n",
    "Note:\n",
    "*I* = The identity matrix\n",
    "\n",
    "Because β is predicting y, it is better to conclude that this derivation represents $\\hat{β}$.\n",
    "\n",
    "This is not the best approach because we are assuming $Xβ$ is full column rank, which may not be true if there is **Multicollinearity**.\n",
    "\n",
    "Why? If one parameter is a linear combination of any of the others, then the design matrix $X$ is not of full column rank (e.g. $β_3 = 4*β_1$).\n",
    "\n",
    "#### **3) Transforming $X$ to Row Canonical Form**\n",
    "\n",
    "The equation\n",
    "\n",
    "$$X^TXβ = X^Ty$$\n",
    "\n",
    "can be row reduced to its canonical form to get the vector of parameters as well.\n",
    "\n",
    "This will make sense in the next derivation.\n",
    "\n",
    "#### **4) Using Orthogonal Projections**\n",
    "\n",
    "$Xβ = y$ can be seen as having a projection and an orthogonal component.\n",
    "\n",
    "If we view the parameters as predictions, then we have a projection:\n",
    "$$X\\hat{β} = \\hat{y}$$\n",
    "\n",
    "This is also known as $\\hat{y}$ projected onto the column space of $X\\hat{β}$\n",
    "\n",
    "The orthogonal component will be the nullspace $X\\hat{β}$, which is the residual: $y - \\hat{y}$ (or $y - X\\hat{β}$)\n",
    "\n",
    "In other words, the *residual* (orthogonal) and *prediction* (projection) add up to the vector of the dependent variable: y\n",
    "\n",
    "What now?\n",
    "\n",
    "Given that $y - X\\hat{β}$ is orthogonal to the column space of $X$, then it's orthogonal to each column of $X$:\n",
    "\n",
    "$$X^T*(y - X\\hat{β}) = 0$$\n",
    "$$X^Ty - X^TX\\hat{β} = 0$$\n",
    "$$X^Ty = X^TX\\hat{β}$$\n",
    "$$(X^TX)^{-1}X^Ty = \\hat{β}$$\n",
    "\n",
    "We could have solved for that using row reduction, where $X^TX$ is augmented by $X^Ty$, then put into row canonical form.\n",
    "\n",
    "#### **Conclusion**\n",
    "\n",
    "Regardless of which approach you use with OLS, the coefficients will be:\n",
    "$$\\hat{β} = (X^TX)^{-1}X^Ty$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- #### **0) How to Get Started**\n",
    "\n",
    "With GD, you must decide a cost function, AKA a loss or an objective function.\n",
    "\n",
    "For multiple regression, we start with the mean square error (MSE) as the cost function (it is most common):\n",
    "\n",
    "$$MSE = \\frac{1}{N} \\sum_{i=1}^N (y_i - \\beta_0 - \\mathbf{x}_i^T \\boldsymbol{\\beta})^2$$\n",
    "\n",
    "Where:\n",
    "\n",
    "*N* := Number of data points\\\n",
    "*y_i* := The vector of the dependent variable\\\n",
    "*β_0* := The scalar of the independent variable's intercept\\\n",
    "*β_i* := The vector of parameters (coefficients to be estimated)\\\n",
    "*x_i* := The vector of independent variables\n",
    "\n",
    "Note: This has not been put in matrix form because GD uses calculus.\n",
    "\n",
    "At first, you might think, \"How can I calculate the residual without first having values for the parameters?\"\n",
    "\n",
    "GD iteratively determines the parameters' values.\n",
    "\n",
    "You add the value of the partial derivative of the MSE with regard to the particular parameter:\n",
    "\n",
    "$$\\frac{\\partial MSE}{\\partial \\beta_0} = -\\frac{2}{N} \\sum_{i=1}^N (y_i - \\beta_0 - \\mathbf{x}_i^T \\boldsymbol{\\beta_i})$$\n",
    "\n",
    "$$\\frac{\\partial MSE}{\\partial {\\beta_i}} = -\\frac{2}{N} \\sum_{i=1}^{N}(y_i - \\beta_0 + \\mathbf{x}_i^T \\boldsymbol{\\beta_i}) * x_i$$\n",
    "\n",
    "Now, let's set the parameters to 0 and add a learning rate (α) and number of times (i.e. epochs) to update each parameter.\n",
    "\n",
    "$\\alpha = 0.01$ will be the learning rate, and $t = 100$ will be the number of epochs.\n",
    "\n",
    "We want to update the model parameters using the following equations:\n",
    "\n",
    "$$\\beta_0^{t+1} = \\beta_0 + \\alpha \\cdot \\frac{\\partial MSE}{\\partial \\beta_0}$$\n",
    "\n",
    "$$\\beta_i^{t+1} = \\beta_i + \\alpha \\cdot \\frac{\\partial MSE}{\\partial \\beta_i}$$\n",
    "\n",
    "Substituting the derivatives we found earlier:\n",
    "\n",
    "$$\\beta_0^{t+1} = \\beta_0^{t+1} + 0.01 \\cdot (-\\frac{2}{N} \\sum_{i=1}^{N}(y_i - (\\beta_0^{t+1} + \\beta_i x_i)))$$\n",
    "\n",
    "$$\\beta_i^{t+1} = \\beta_i + 0.01 \\cdot (-\\frac{2}{N} \\sum_{i=1}^{N}(y_i - (\\boldsymbol{\\beta_0} + \\beta_i \\boldsymbol{x_i})) \\cdot \\boldsymbol{x_i})$$\n",
    "\n",
    "Simplifying the equations:\n",
    "\n",
    "$$\\beta_0^{t+1} = \\beta_0 - 0.02 \\sum_{i=1}^{N}(y_i - (\\boldsymbol{\\beta_0} + \\beta_i \\boldsymbol{x_i}))$$\n",
    "\n",
    "$$\\beta_i^{t+1} = \\beta_i - 0.02 \\sum_{i=1}^{N}(y_i - (\\boldsymbol{\\beta_0} + \\beta_i \\boldsymbol{x_i})) \\cdot \\boldsymbol{x_i}$$ -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **How to Use Gradient Descent (GD)**\n",
    "\n",
    "#### **0) How to Get Started**\n",
    "\n",
    "To perform Gradient Descent (GD), you must first decide on a cost function, also known as a loss or objective function.\n",
    "\n",
    "For multiple regression, we typically use the mean squared error (MSE) as the cost function:\n",
    "\n",
    "$$MSE = \\frac{1}{N} \\| \\mathbf{y} - \\beta_0 \\mathbf{1} - \\mathbf{X} \\boldsymbol{\\beta} \\|^2$$\n",
    "\n",
    "Where:\n",
    "\n",
    "*N* := Number (scalar) of data points\\\n",
    "*y* := Vector of dependent variables (N * 1)\\\n",
    "*β_0* := Scalar intercept term\\\n",
    "*1* := Vector of 1's (n * 1)\\\n",
    "*X* := Matrix of independent variables (M * N)\\\n",
    "*β* := Vector of parameters (coefficients to be estimated, N * 1)\n",
    "\n",
    "At first, you might think, \"How can I calculate the residual without first having values for the parameters?\"\n",
    "\n",
    "GD iteratively determines the parameters' values updating the parameters at each step based on the gradient of the cost function, which, in this case, is the MSE.\n",
    "\n",
    "You add the value of the partial derivative of the MSE with regard to the particular parameter:\n",
    "\n",
    "$$\\frac{\\partial MSE}{\\partial \\beta_0} = -\\frac{2}{N} \\mathbf{1}^T (\\mathbf{y} - \\beta_0 \\mathbf{1} - \\mathbf{X} \\boldsymbol{\\beta})$$\n",
    "\n",
    "$$\\frac{\\partial MSE}{\\partial \\boldsymbol{\\beta}} = -\\frac{2}{N} \\mathbf{X}^T (\\mathbf{y} - \\beta_0 \\mathbf{1} - \\mathbf{X} \\boldsymbol{\\beta})$$\n",
    "\n",
    "Now, let's set the parameters to 0 and add a learning rate (α) and number of times (i.e. epochs) to update each parameter.\n",
    "\n",
    "$α = 0.01$ will be the learning rate, and $t = 100$ will be the number of epochs.\n",
    "\n",
    "The updates for the parameters are:\n",
    "\n",
    "$$\\beta_0^{(t+1)} = \\beta_0^{(t)} - \\alpha \\cdot \\frac{\\partial MSE}{\\partial \\beta_0}$$\n",
    "\n",
    "$$\\boldsymbol{\\beta}^{(t+1)} = \\boldsymbol{\\beta}^{(t)} - \\alpha \\cdot \\frac{\\partial MSE}{\\partial \\boldsymbol{\\beta}}$$\n",
    "\n",
    "Substituting the derivatives into the update equations:\n",
    "\n",
    "$$\\beta_0^{(t+1)} = \\beta_0^{(t)} + \\frac{2 \\alpha}{N} \\mathbf{1}^T (\\mathbf{y} - \\beta_0^{(t)} \\mathbf{1} - \\mathbf{X} \\boldsymbol{\\beta}^{(t)})$$\n",
    "\n",
    "$$\\boldsymbol{\\beta}^{(t+1)} = \\boldsymbol{\\beta}^{(t)} + \\frac{2 \\alpha}{N} \\mathbf{X}^T (\\mathbf{y} - \\beta_0^{(t)} \\mathbf{1} - \\mathbf{X} \\boldsymbol{\\beta}^{(t)})$$\n",
    "\n",
    "#### **Conclusion**\n",
    "\n",
    "The expressions $\\beta_0^{(t+1)}$ and $\\boldsymbol{\\beta}^{(t+1)}$ would give us the intercept and vector of parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Gathering the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset comes from [Kaggle](https://www.kaggle.com/datasets/nikhil7280/student-performance-multiple-linear-regression).\n",
    "\n",
    "The dataset examines the factors influencing academic student performance, including:\n",
    "- Hours Studied: The total number of hours spent studying by each student.\n",
    "- Previous Scores: The scores obtained by students in previous tests.\n",
    "- Extracurricular Activities: Whether the student participates in extracurricular activities (Yes or No).\n",
    "- Sleep Hours: The average number of hours of sleep the student had per day.\n",
    "- Sample Question Papers Practiced: The number of sample question papers the student practiced.\n",
    "\n",
    "The dataset consists of 10,000 student records, with each record containing information about various predictors and a performance index.\n",
    "\n",
    "The target variable, performance index, measures each student's overall performance. The index, rounded to the nearest integer, ranges from 10 to 100, with higher values indicating better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/nikhil7280/student-performance-multiple-linear-regression?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48.5k/48.5k [00:00<00:00, 20.5MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n",
      "Path to dataset files: /Users/alexdubro/.cache/kagglehub/datasets/nikhil7280/student-performance-multiple-linear-regression/versions/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# The dataset will come from Kaggle:\n",
    "\n",
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"nikhil7280/student-performance-multiple-linear-regression\")\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import os\n",
    "import pandas as pd \n",
    "from scipy.linalg import pinv\n",
    "import seaborn as sns \n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hours Studied</th>\n",
       "      <th>Previous Scores</th>\n",
       "      <th>Extracurricular Activities</th>\n",
       "      <th>Sleep Hours</th>\n",
       "      <th>Sample Question Papers Practiced</th>\n",
       "      <th>Performance Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>99</td>\n",
       "      <td>Yes</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>91.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>82</td>\n",
       "      <td>No</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>51</td>\n",
       "      <td>Yes</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>52</td>\n",
       "      <td>Yes</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>75</td>\n",
       "      <td>No</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Hours Studied  Previous Scores Extracurricular Activities  Sleep Hours  \\\n",
       "0              7               99                        Yes            9   \n",
       "1              4               82                         No            4   \n",
       "2              8               51                        Yes            7   \n",
       "3              5               52                        Yes            5   \n",
       "4              7               75                         No            8   \n",
       "\n",
       "   Sample Question Papers Practiced  Performance Index  \n",
       "0                                 1               91.0  \n",
       "1                                 2               65.0  \n",
       "2                                 2               45.0  \n",
       "3                                 2               36.0  \n",
       "4                                 5               66.0  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path = os.path.join(path, 'Student_Performance.csv')\n",
    "\n",
    "raw_data = pd.read_csv(dataset_path)\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Cleaning/preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Removing null data\n",
    "\n",
    "raw_data.dropna(inplace=True)\n",
    "\n",
    "# 2) Removing duplicates\n",
    "\n",
    "raw_data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because there is a categorical variable, the data must be dummy coded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Extracurricular Activities\n",
       "No     4986\n",
       "Yes    4887\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data['Extracurricular Activities'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hours Studied</th>\n",
       "      <th>Previous Scores</th>\n",
       "      <th>Sleep Hours</th>\n",
       "      <th>Sample Question Papers Practiced</th>\n",
       "      <th>Performance Index</th>\n",
       "      <th>Extracurricular Activities_No</th>\n",
       "      <th>Extracurricular Activities_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>99</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>82</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>51</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>52</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>75</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Hours Studied  Previous Scores  Sleep Hours  \\\n",
       "0              7               99            9   \n",
       "1              4               82            4   \n",
       "2              8               51            7   \n",
       "3              5               52            5   \n",
       "4              7               75            8   \n",
       "\n",
       "   Sample Question Papers Practiced  Performance Index  \\\n",
       "0                                 1               91.0   \n",
       "1                                 2               65.0   \n",
       "2                                 2               45.0   \n",
       "3                                 2               36.0   \n",
       "4                                 5               66.0   \n",
       "\n",
       "   Extracurricular Activities_No  Extracurricular Activities_Yes  \n",
       "0                              0                               1  \n",
       "1                              1                               0  \n",
       "2                              0                               1  \n",
       "3                              0                               1  \n",
       "4                              1                               0  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_data = pd.get_dummies(raw_data, columns=['Extracurricular Activities'], dtype=int)\n",
    "updated_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Targeting data\n",
    "\n",
    "y = updated_data['Performance Index']\n",
    "X = updated_data.drop('Performance Index', axis=1)\n",
    "cols = ['Intercept'] + X.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept                          -138.946289\n",
       "Hours Studied                         2.855284\n",
       "Previous Scores                       1.018782\n",
       "Sleep Hours                           0.541864\n",
       "Sample Question Papers Practiced      0.243364\n",
       "Extracurricular Activities_No        68.990479\n",
       "Extracurricular Activities_Yes       66.042480\n",
       "dtype: float64"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_with_intercept = np.column_stack([np.ones(len(X)), X])\n",
    "X_transpose = np.transpose(X_with_intercept)\n",
    "\n",
    "beta_encoding_numpy = np.linalg.inv(X_transpose @ X_with_intercept) @ X_transpose @ y\n",
    "\n",
    "pd.Series(data=beta_encoding_numpy, index=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SciPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept                          -22.507045\n",
       "Hours Studied                        2.852729\n",
       "Previous Scores                      1.018319\n",
       "Sleep Hours                          0.480321\n",
       "Sample Question Papers Practiced     0.193910\n",
       "Extracurricular Activities_No      -11.561869\n",
       "Extracurricular Activities_Yes     -10.945176\n",
       "dtype: float64"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_encoding_scipy = pinv(X_transpose @ X_with_intercept) @ X_transpose @ y\n",
    "\n",
    "pd.Series(data=beta_encoding_scipy, index=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $R^2$ Statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 statistic: 0.9886813814840943\n"
     ]
    }
   ],
   "source": [
    "# R-squared\n",
    "\n",
    "arr_result = X_with_intercept @ beta_encoding_scipy\n",
    "y_i = np.array(y)\n",
    "squared_res = ((y_i - arr_result)**2)\n",
    "ss_res = sum(squared_res)\n",
    "\n",
    "y_mean = updated_data['Performance Index'].mean()\n",
    "y_mean_repeated = np.repeat(y_mean, y_i.shape[0])\n",
    "squared_tot = ((y_i - y_mean_repeated)**2)\n",
    "ss_tot = sum(squared_tot)\n",
    "\n",
    "r_squared = 1 - (ss_res/ss_tot)\n",
    "print(\"R^2 statistic:\", r_squared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $F$-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-test statistic: 143632.5245290524\n"
     ]
    }
   ],
   "source": [
    "# Calculate SS_reg (explained variance)\n",
    "y_mean = y.mean()\n",
    "y_pred = np.dot(X_with_intercept, beta_encoding_scipy)\n",
    "ss_reg = sum((y_pred - y_mean) ** 2)\n",
    "\n",
    "# Calculate SS_res (unexplained variance)\n",
    "ss_res = sum((y - y_pred) ** 2)\n",
    "\n",
    "# Number of predictors (k) and observations (n)\n",
    "n = len(y)\n",
    "k = X_with_intercept.shape[1] - 1  # Exclude intercept\n",
    "\n",
    "# F-statistic calculation\n",
    "numerator = ss_reg / k\n",
    "denominator = ss_res / (n - k - 1)\n",
    "f_test = numerator / denominator\n",
    "\n",
    "print(\"F-test statistic:\", f_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-test statistic: 143632.5245290118\n"
     ]
    }
   ],
   "source": [
    "# F-test\n",
    "\n",
    "n = len(y)  # Number of observations\n",
    "k = len(X.columns) # Number of predictors (excluding intercept)\n",
    "\n",
    "# Assuming r_squared and ss_res (sum of squared residuals) are already calculated\n",
    "numerator = r_squared / k\n",
    "denominator = (1 - r_squared) / (n - k - 1)\n",
    "\n",
    "f_test = numerator / denominator\n",
    "print(\"F-test statistic:\", f_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:      Performance Index   R-squared:                       0.989\n",
      "Model:                            OLS   Adj. R-squared:                  0.989\n",
      "Method:                 Least Squares   F-statistic:                 1.724e+05\n",
      "Date:                Fri, 13 Dec 2024   Prob (F-statistic):               0.00\n",
      "Time:                        03:26:34   Log-Likelihood:                -21065.\n",
      "No. Observations:                9873   AIC:                         4.214e+04\n",
      "Df Residuals:                    9867   BIC:                         4.219e+04\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "====================================================================================================\n",
      "                                       coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "const                              -22.5070      0.084   -267.026      0.000     -22.672     -22.342\n",
      "Hours Studied                        2.8527      0.008    358.940      0.000       2.837       2.868\n",
      "Previous Scores                      1.0183      0.001    857.427      0.000       1.016       1.021\n",
      "Sleep Hours                          0.4803      0.012     39.623      0.000       0.457       0.504\n",
      "Sample Question Papers Practiced     0.1939      0.007     27.017      0.000       0.180       0.208\n",
      "Extracurricular Activities_No      -11.5619      0.047   -246.311      0.000     -11.654     -11.470\n",
      "Extracurricular Activities_Yes     -10.9452      0.047   -233.558      0.000     -11.037     -10.853\n",
      "==============================================================================\n",
      "Omnibus:                        3.123   Durbin-Watson:                   2.003\n",
      "Prob(Omnibus):                  0.210   Jarque-Bera (JB):                3.224\n",
      "Skew:                           0.014   Prob(JB):                        0.200\n",
      "Kurtosis:                       3.084   Cond. No.                     1.96e+17\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 1.34e-27. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "X_constant = sm.add_constant(X)\n",
    "\n",
    "model = sm.OLS(y, X_constant).fit()\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual F-test statistic: 172376.49943577044\n"
     ]
    }
   ],
   "source": [
    "r_squared = model.rsquared\n",
    "k = model.df_model  # Number of predictors\n",
    "n_k_1 = model.df_resid  # Degrees of freedom for residuals\n",
    "\n",
    "numerator = r_squared / k\n",
    "denominator = (1 - r_squared) / n_k_1\n",
    "\n",
    "f_test_manual = numerator / denominator\n",
    "print(\"Manual F-test statistic:\", f_test_manual)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2.196781\n",
      "1    0.816815\n",
      "2   -1.500169\n",
      "3   -0.265685\n",
      "4   -1.163862\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "y = updated_data['Performance Index']\n",
    "X = updated_data.drop(['Performance Index', 'Extracurricular Activities_No'], axis=1)\n",
    "x_transpose = np.transpose(X)\n",
    "\n",
    "beta_no = np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "print(beta_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2.204571\n",
      "1    0.819236\n",
      "2   -1.442300\n",
      "3   -0.266282\n",
      "4   -2.322921\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "y = updated_data['Performance Index']\n",
    "X = updated_data.drop(['Performance Index', 'Extracurricular Activities_Yes'], axis=1)\n",
    "x_transpose = np.transpose(X)\n",
    "\n",
    "beta_yes = np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "print(beta_yes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_data = raw_data.copy()  # making a copy so that our original data remains intact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_data['Extracurricular Activities'] = raw_data['Extracurricular Activities'].map({'No': 0, 'Yes': 1}) # dummy coding the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_0 = updated_data[updated_data['Extracurricular Activities'] == 0]\n",
    "data_0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_0 = data_0.drop('Performance Index', axis=1) # Extracurricular Activities: 'No': 0\n",
    "y_0 = data_0['Performance Index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = updated_data[updated_data['Extracurricular Activities'] == 1]\n",
    "data_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1 = data_1.drop('Performance Index', axis=1)\n",
    "y_1 = data_1['Performance Index']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Visualizing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hours Studied</th>\n",
       "      <th>Previous Scores</th>\n",
       "      <th>Sleep Hours</th>\n",
       "      <th>Sample Question Papers Practiced</th>\n",
       "      <th>Performance Index</th>\n",
       "      <th>Extracurricular Activities_No</th>\n",
       "      <th>Extracurricular Activities_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9873.000000</td>\n",
       "      <td>9873.000000</td>\n",
       "      <td>9873.000000</td>\n",
       "      <td>9873.000000</td>\n",
       "      <td>9873.000000</td>\n",
       "      <td>9873.000000</td>\n",
       "      <td>9873.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.992100</td>\n",
       "      <td>69.441102</td>\n",
       "      <td>6.531652</td>\n",
       "      <td>4.583004</td>\n",
       "      <td>55.216651</td>\n",
       "      <td>0.505014</td>\n",
       "      <td>0.494986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.589081</td>\n",
       "      <td>17.325601</td>\n",
       "      <td>1.697683</td>\n",
       "      <td>2.867202</td>\n",
       "      <td>19.208570</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Hours Studied  Previous Scores  Sleep Hours  \\\n",
       "count    9873.000000      9873.000000  9873.000000   \n",
       "mean        4.992100        69.441102     6.531652   \n",
       "std         2.589081        17.325601     1.697683   \n",
       "min         1.000000        40.000000     4.000000   \n",
       "25%         3.000000        54.000000     5.000000   \n",
       "50%         5.000000        69.000000     7.000000   \n",
       "75%         7.000000        85.000000     8.000000   \n",
       "max         9.000000        99.000000     9.000000   \n",
       "\n",
       "       Sample Question Papers Practiced  Performance Index  \\\n",
       "count                       9873.000000        9873.000000   \n",
       "mean                           4.583004          55.216651   \n",
       "std                            2.867202          19.208570   \n",
       "min                            0.000000          10.000000   \n",
       "25%                            2.000000          40.000000   \n",
       "50%                            5.000000          55.000000   \n",
       "75%                            7.000000          70.000000   \n",
       "max                            9.000000         100.000000   \n",
       "\n",
       "       Extracurricular Activities_No  Extracurricular Activities_Yes  \n",
       "count                    9873.000000                     9873.000000  \n",
       "mean                        0.505014                        0.494986  \n",
       "std                         0.500000                        0.500000  \n",
       "min                         0.000000                        0.000000  \n",
       "25%                         0.000000                        0.000000  \n",
       "50%                         1.000000                        0.000000  \n",
       "75%                         1.000000                        1.000000  \n",
       "max                         1.000000                        1.000000  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.hist(df['MEDV'], bins=50, ec='black', rwidth=0.5)\n",
    "plt.xlabel('Price in thousands')\n",
    "plt.ylabel('Number of houses')\n",
    "plt.title(\"Counts of Housing Prices\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Training & Building the Algorithm: Deriving Parameters Using OLS & GD "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordinary Least Squares (OLS)\n",
    "\n",
    "We will be using the following equation to derive the parameters for OLS:\n",
    "\n",
    "$$\\hat{β} = (X^TX)^{-1}X^Ty$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_0 = data_0['Performance Index']\n",
    "# X_0 = data_0.drop('Performance Index', axis=1)\n",
    "# x_0_transpose = np.transpose(X_0)\n",
    "\n",
    "# beta = np.linalg.inv(X_0.T @ X_0) @ X_0.T @ y_0\n",
    "\n",
    "# Correct implementation of normal equations\n",
    "X_0 = data_0.drop('Performance Index', axis=1)\n",
    "y_0 = data_0['Performance Index']\n",
    "\n",
    "# Add a column of 1s for the intercept term\n",
    "X_0_with_intercept = np.column_stack([np.ones(len(X_0)), X_0])\n",
    "\n",
    "# Use matrix multiplication and matrix inverse\n",
    "beta = np.linalg.inv(X_0_with_intercept.T @ X_0_with_intercept) @ X_0_with_intercept.T @ y_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of Extracurricular Activities (namely, the dummy variable), the matrix is not full column rank. Therefore, other approaches must be taken to calculate its parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_regression(X, y, lambda_=1.0):\n",
    "    # Add intercept column\n",
    "    X_with_intercept = np.column_stack([np.ones(len(X)), X])\n",
    "    \n",
    "    # Create identity matrix (skip first element for intercept)\n",
    "    I = np.eye(X_with_intercept.shape[1])\n",
    "    I[0,0] = 0  # Don't regularize intercept\n",
    "    \n",
    "    # Solve (X^T X + λI)^(-1) X^T y\n",
    "    beta = np.linalg.inv(X_with_intercept.T @ X_with_intercept + lambda_ * I) @ X_with_intercept.T @ y\n",
    "    \n",
    "    return beta\n",
    "\n",
    "parameters = ridge_regression(X_0, y_0, lambda_=1.0)\n",
    "print(parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Singular Value Decomposition (SVD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U, s, Vt = np.linalg.svd(X_0_with_intercept, full_matrices=False)\n",
    "\n",
    "# Create a diagonal matrix with reciprocals of singular values\n",
    "# Add a small threshold to handle near-zero singular values\n",
    "s_inv = np.zeros_like(s)\n",
    "threshold = 1e-10  # You can adjust this threshold\n",
    "s_inv[s > threshold] = 1 / s[s > threshold]\n",
    "\n",
    "# Construct the pseudoinverse\n",
    "# V * Σ⁺ * U^T\n",
    "pseudoinverse = Vt.T @ np.diag(s_inv) @ U.T\n",
    "\n",
    "# Compute beta\n",
    "beta = pseudoinverse @ y_0\n",
    "print(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_0 = data_0['Performance Index']\n",
    "# X_0 = data_0.drop('Performance Index', axis=1)\n",
    "# x_0_transpose = np.transpose(X_0)\n",
    "\n",
    "beta_11 = np.linalg.inv(X_0.T @ X_0) @ X_0.T @ y_0\n",
    "print(beta_11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct implementation of normal equations\n",
    "# X_1 = data_1.drop('Performance Index', axis=1)\n",
    "# y_1 = data_1['Performance Index']\n",
    "\n",
    "# Add a column of 1s for the intercept term\n",
    "X_1_with_intercept = np.column_stack([np.ones(len(X_1)), X_1])\n",
    "\n",
    "# Use matrix multiplication and matrix inverse\n",
    "beta_22 = np.linalg.inv(X_1_with_intercept.T @ X_1_with_intercept) @ X_1_with_intercept.T @ y_1\n",
    "print(beta_22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_regression(X, y, lambda_=1.0):\n",
    "    # Add intercept column\n",
    "    X_with_intercept = np.column_stack([np.ones(len(X)), X])\n",
    "    \n",
    "    # Create identity matrix (skip first element for intercept)\n",
    "    I = np.eye(X_with_intercept.shape[1])\n",
    "    I[0,0] = 0  # Don't regularize intercept\n",
    "    \n",
    "    # Solve (X^T X + λI)^(-1) X^T y\n",
    "    beta = np.linalg.inv(X_with_intercept.T @ X_with_intercept + lambda_ * I) @ X_with_intercept.T @ y\n",
    "    \n",
    "    return beta\n",
    "\n",
    "parameters = ridge_regression(X_1, y_1, lambda_=1.0)\n",
    "print(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U, s, Vt = np.linalg.svd(X_1_with_intercept, full_matrices=False)\n",
    "\n",
    "# Create a diagonal matrix with reciprocals of singular values\n",
    "# Add a small threshold to handle near-zero singular values\n",
    "s_inv = np.zeros_like(s)\n",
    "threshold = 1e-10  # You can adjust this threshold\n",
    "s_inv[s > threshold] = 1 / s[s > threshold]\n",
    "\n",
    "# Construct the pseudoinverse\n",
    "# V * Σ⁺ * U^T\n",
    "pseudoinverse = Vt.T @ np.diag(s_inv) @ U.T\n",
    "\n",
    "# Compute beta\n",
    "beta = pseudoinverse @ y_1\n",
    "print(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "miniforge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
